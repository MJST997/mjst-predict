{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, LSTM, Dense,Bidirectional\n",
    "from tensorflow.keras.layers import Conv1D, Reshape, Bidirectional, LSTM, Dropout, Dense, LayerNormalization\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "from tensorflow.keras.layers import Conv1D, Reshape, Bidirectional, GRU, Dropout, Dense, LayerNormalization\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv(\"model_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['company_code',\n",
    " 'dale_chill_formula',\n",
    " 'flesch_score',\n",
    " 'gunnning_fog_score',\n",
    " 'verb_count',\n",
    " 'noun_count',\n",
    " 'adjective_count',\n",
    " 'len_text',\n",
    " 'len_text_words',\n",
    " 'len_mentions',\n",
    " 'score_group',\n",
    " 'prev_likes',\n",
    " 'avg_comp_likes',\n",
    " 'moving_avg_likes',\n",
    " 'Followers',\n",
    " 'hashtag_count',\n",
    " 'sadness', 'joy', 'love', 'anger', 'fear', 'surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = corpus[features]\n",
    "y = corpus[\"like_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl = tf.keras.losses.KLDivergence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('vinai/bertweet-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = tokenizer(corpus['lemmatized_text'].tolist(),add_special_tokens=True, truncation=True, padding='max_length', max_length=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined = pd.concat([X, pd.DataFrame(X_text[\"input_ids\"])], axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_combined.values, y.values, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (-1, X_train.shape[0], X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (-1, X_test.shape[0], X_test.shape[1]))\n",
    "\n",
    "X_train = np.transpose(X_train, (1, 0, 2))\n",
    "X_test = np.transpose(X_test, (1, 0, 2))\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model_lstm = Sequential()\n",
    "\n",
    "# 1st Conv1D layer with 128 filters, kernel size of 3, ReLU activation, and 'same' padding\n",
    "model_lstm.add(Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=(1, 534), padding=\"same\"))\n",
    "\n",
    "# Add LayerNormalization to stabilize training and improve generalization\n",
    "model_lstm.add(LayerNormalization())\n",
    "\n",
    "# 2nd Conv1D layer with 256 filters, kernel size of 3, ReLU activation, and 'same' padding\n",
    "model_lstm.add(Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'))\n",
    "\n",
    "# Add LayerNormalization again\n",
    "model_lstm.add(LayerNormalization())\n",
    "\n",
    "# Reshape the output to fit the LSTM layer input requirements\n",
    "model_lstm.add(Reshape((-1, 256)))\n",
    "\n",
    "# Add a Bidirectional LSTM layer with 128 units and return sequences\n",
    "model_lstm.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
    "\n",
    "# Add a dropout layer with a rate of 0.3\n",
    "model_lstm.add(Dropout(0.3))\n",
    "\n",
    "# Add a second Bidirectional LSTM layer with 64 units\n",
    "model_lstm.add(Bidirectional(LSTM(units=64)))\n",
    "\n",
    "# Add a dropout layer with a rate of 0.3\n",
    "model_lstm.add(Dropout(0.3))\n",
    "\n",
    "# Add a Dense layer with 32 units and ReLU activation\n",
    "model_lstm.add(Dense(units=32, activation='relu'))\n",
    "\n",
    "# Add a dropout layer with a rate of 0.3\n",
    "model_lstm.add(Dropout(0.3))\n",
    "\n",
    "# And a Dense output layer with 1 unit and linear activation for regression\n",
    "model_lstm.add(Dense(units=1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model_gru = Sequential()\n",
    "\n",
    "# 1st Conv1D layer with 128 filters, kernel size of 3, ReLU activation, and 'same' padding\n",
    "model_gru.add(Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=(1, 512), padding=\"same\"))\n",
    "\n",
    "# Add LayerNormalization to stabilize training and improve generalization\n",
    "model_gru.add(LayerNormalization())\n",
    "\n",
    "# 2nd Conv1D layer with 256 filters, kernel size of 3, ReLU activation, and 'same' padding\n",
    "model_gru.add(Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'))\n",
    "\n",
    "# Add LayerNormalization again\n",
    "model_gru.add(LayerNormalization())\n",
    "\n",
    "# Reshape the output to fit the GRU layer input requirements\n",
    "model_gru.add(Reshape((-1, 256)))\n",
    "\n",
    "# Add a Bidirectional GRU layer with 128 units and return sequences\n",
    "model_gru.add(Bidirectional(GRU(units=128, return_sequences=True)))\n",
    "\n",
    "# Add a dropout layer with a rate of 0.3\n",
    "model_gru.add(Dropout(0.3))\n",
    "\n",
    "# Add a second Bidirectional GRU layer with 64 units\n",
    "model_gru.add(Bidirectional(GRU(units=64)))\n",
    "\n",
    "# Add a dropout layer with a rate of 0.3\n",
    "model_gru.add(Dropout(0.3))\n",
    "\n",
    "# Add a Dense layer with 32 units and ReLU activation\n",
    "model_gru.add(Dense(units=32, activation='relu'))\n",
    "\n",
    "# Add a dropout layer with a rate of 0.3\n",
    "model_gru.add(Dropout(0.3))\n",
    "\n",
    "# Add a Dense output layer with 1 unit and linear activation for regression\n",
    "model_gru.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "# Compile the model with the Adam optimizer, mean squared error loss, and mean absolute error metric\n",
    "model_gru.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.compile(\n",
    "    optimizer='adam',  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss='mse',\n",
    "    # List of metrics to monitor\n",
    "    metrics=[kl,tf.keras.metrics.MeanAbsoluteError() ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru.compile(\n",
    "    optimizer='adam',  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss='mse',\n",
    "    # List of metrics to monitor\n",
    "    metrics=[kl,tf.keras.metrics.MeanAbsoluteError() ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model_lstm.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=3,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    #validation_data=(X_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model_gru.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=3,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    #validation_data=(X_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predictions = model_lstm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_predictions = model_gru.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(X_train, y_train) # or gru_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_preds = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_preds = (lstm_predictions + xgb_preds) / 2\n",
    "ensemble_preds_xgb_lstm = ensemble_preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_preds = (gru_predictions + xgb_preds) / 2\n",
    "ensemble_preds_xgb_gru = ensemble_preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_en_lstm_xgboost = r2_score(y_test, ensemble_preds_xgb_lstm)\n",
    "r2_en_gru_xgboost = r2_score(y_test, ensemble_preds_xgb_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_en_lstm_xgboost,r2_en_gru_xgboost)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
